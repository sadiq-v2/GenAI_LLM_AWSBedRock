{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4445238b-be33-4e66-ba80-127a9594b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('postgresql_connection') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae05f4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- full_ancestral_name: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "| full_ancestral_name|\n",
      "+--------------------+\n",
      "|Software - Busine...|\n",
      "|  Software - Ed Tech|\n",
      "|  Software - FinTech|\n",
      "|   Healthcare - HCIT|\n",
      "|Software - IT Inf...|\n",
      "|Software - Intern...|\n",
      "| Software - MegaTech|\n",
      "|   Software - Mobile|\n",
      "| Software - Payments|\n",
      "|Software - SaaS/C...|\n",
      "| Software - Security|\n",
      "|Internet - Advert...|\n",
      "|CEO/BOD - General...|\n",
      "|Internet - E-Comm...|\n",
      "|  Internet - Ed Tech|\n",
      "|        10/10 Gender|\n",
      "|Internet - Market...|\n",
      "| Internet - MegaTech|\n",
      "|   Internet - Mobile|\n",
      "|       CT - Biofuels|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read CSV file into a DataFrame\n",
    "df = spark.read.csv(\"/home/jovyan/work/utility/tags.csv\", header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "# Show the DataFrame schema and first few rows\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d81dd4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funding_rounds no-> 43\n",
      "sector no-> 465\n"
     ]
    }
   ],
   "source": [
    "# Domains\n",
    "domains = [\n",
    "    \"B2B\",\n",
    "    \"B2C\",\n",
    "    \"E-commerce\",\n",
    "    \"Healthcare\",\n",
    "    \"Technology\",\n",
    "    \"Finance\",\n",
    "    \"Education\",\n",
    "    \"Real Estate\",\n",
    "    \"Hospitality\",\n",
    "    \"Automotive\"\n",
    "]\n",
    "\n",
    "# Sectors\n",
    "sectors = [\n",
    "    \"Personal Finance\", \"Virtual Reality\", \"Eyewear\", \"Franchise\", \"Cloud Infrastructure\",\n",
    "    \"DSP\", \"Internet of Things\", \"Drones\", \"Digital Marketing\", \"Fuel Cell\", \"Health Care\",\n",
    "    \"Product Management\", \"Water\", \"Credit Cards\", \"Education\", \"Wellness\", \"Broadcasting\",\n",
    "    \"Visual Search\", \"Navigation\", \"Film Production\", \"Music Streaming\", \"Home Improvement\",\n",
    "    \"Sporting Goods\", \"Collaboration\", \"Sales\", \"Wine And Spirits\", \"Semiconductor\", \"Ticketing\",\n",
    "    \"Service Industry\", \"Casual Games\", \"Bakery\", \"Ethereum\", \"Fantasy Sports\", \"Gaming\",\n",
    "    \"Real Estate Investment\", \"Tea\", \"Concerts\", \"Speech Recognition\", \"Enterprise Applications\",\n",
    "    \"Pharmaceutical\", \"TV\", \"Wireless\", \"B2C\", \"E-Commerce Platforms\", \"Cloud Management\",\n",
    "    \"Data Storage\", \"Innovation Management\", \"Art\", \"Video Streaming\", \"Apps\", \"Video\",\n",
    "    \"Management Information Systems\", \"Information Services\", \"Web Design\", \"Organic\",\n",
    "    \"Retail Technology\", \"EdTech\", \"Operating Systems\", \"Insurance\", \"Food Delivery\",\n",
    "    \"Employee Benefits\", \"SEO\", \"Financial Services\", \"Parks\", \"Payments\", \"Security\",\n",
    "    \"Satellite Communication\", \"Fashion\", \"Chemical\", \"HRTech\", \"Brand Marketing\",\n",
    "    \"Consumer Electronics\", \"Energy\", \"Mobile Payments\", \"Machine Learning\", \"Incubators\",\n",
    "    \"Public Safety\", \"Data Center\", \"Foundries\", \"Consumer Research\", \"Residential\",\n",
    "    \"Natural Resources\", \"Content Creators\", \"Made to Order\", \"Consumer Goods\",\n",
    "    \"Wealth Management\", \"Medical Device\", \"CivicTech\", \"Resorts\", \"Image Recognition\",\n",
    "    \"Sports\", \"Reservations\", \"Consumer Lending\", \"Car Sharing\", \"Cloud Computing\",\n",
    "    \"Trading Platform\", \"Developer Platform\", \"Business Development\", \"Test and Measurement\",\n",
    "    \"Autonomous Vehicles\", \"Plastics and Rubber Manufacturing\", \"Career Planning\",\n",
    "    \"Data Center Automation\", \"Peer to Peer\", \"Renewable Energy\", \"Information Technology\",\n",
    "    \"Property Management\", \"IT Management\", \"Marketing Automation\", \"Government\",\n",
    "    \"Fossil Fuels\", \"Mining\", \"Application Performance Management\", \"Baby\",\n",
    "    \"Subscription Service\", \"Mining Technology\", \"Publishing\", \"Building Maintenance\",\n",
    "    \"Oil and Gas\", \"Motion Capture\", \"Property Development\", \"Travel\", \"Mobility Tech\",\n",
    "    \"Finance\", \"Enterprise Software\", \"GovTech\", \"Impact Investing\", \"Ad Network\",\n",
    "    \"Diabetes\", \"Social Media Advertising\", \"Real Estate\", \"CAD\", \"Internet\", \"Product Design\",\n",
    "    \"Amusement Park and Arcade\", \"Solar\", \"Indoor Positioning\", \"Fortune-500\", \"Wind Energy\",\n",
    "    \"Product Search\", \"Semantic Search\", \"Delivery\", \"Internet Radio\", \"Construction Technology\",\n",
    "    \"Email\", \"Printing\", \"Price Comparison\", \"Racing\", \"Grocery\", \"Vacation Rental\",\n",
    "    \"Cryptocurrency\", \"Ride Sharing\", \"Public Relations\", \"Electronics\", \"Video Games\",\n",
    "    \"Organic Food\", \"Embedded Systems\", \"Self-Storage\", \"ISP\", \"Property Insurance\",\n",
    "    \"Craft Beer\", \"Text Analytics\", \"Collaborative Consumption\", \"Market Research\",\n",
    "    \"Online Portals\", \"Venture Capital Firms\", \"Family\", \"Digital Media\", \"Recruiting\",\n",
    "    \"Fitness\", \"Predictive Analytics\", \"Call Center\", \"Web Hosting\", \"Professional Services\",\n",
    "    \"Outsourcing\", \"Consumer\", \"Corporate Training\", \"Rental\", \"Graphic Design\", \"SMS\",\n",
    "    \"Aerospace\", \"Direct Marketing\", \"Social Bookmarking\", \"Packaging Services\", \"Advertising\",\n",
    "    \"Clean Energy\", \"HealthTech\", \"Communities\", \"Nutrition\", \"Outpatient Care\", \"Social Media\",\n",
    "    \"Fraud Detection\", \"Online Games\", \"Real Estate Tech\", \"File Sharing\", \"CleanTech\",\n",
    "    \"Domain Registrar\", \"Leasing\", \"Guides\", \"Brewing\", \"Social\", \"Green Consumer Goods\",\n",
    "    \"Film\", \"Gambling\", \"Crowdsourcing\", \"Sustainability\", \"Recreational Vehicles\",\n",
    "    \"Industrial Design\", \"Shopping\", \"Lending\", \"Asset Management\", \"Automotive\",\n",
    "    \"Developer APIs\", \"Nuclear\", \"Building Material\", \"Smart Building\", \"Employment\",\n",
    "    \"Mineral\", \"Retirement\", \"Industrial\", \"Construction\", \"Photo Editing\",\n",
    "    \"Communications Infrastructure\", \"Psychology\", \"Customer Service\", \"Dental\", \"Auctions\",\n",
    "    \"Private Equity Firms\", \"Credit\", \"Marketing Tech\", \"Content Discovery\",\n",
    "    \"Chemical Engineering\", \"Technical Support\", \"Biotechnology\", \"Hotel\", \"Delivery Service\",\n",
    "    \"Computer\", \"Precious Metals\", \"InsurTech\", \"Video Advertising\", \"Animal Feed\", \"Analytics\",\n",
    "    \"Legal\", \"Supply Chain Technology\", \"Tutoring\", \"Augmented Reality\", \"Digital Entertainment\",\n",
    "    \"Dietary Supplements\", \"GreenTech\", \"Venture Capital\", \"Flash Storage\", \"Language Learning\",\n",
    "    \"Laser\", \"Telecommunications\", \"Training\", \"Home Services\", \"Direct Sales\",\n",
    "    \"Identity Management\", \"Content Delivery Network\", \"Restaurant Tech\", \"Ad Targeting\",\n",
    "    \"Blogging Platforms\", \"Restaurants\", \"Task Management\", \"Cannabis\", \"Knowledge Management\",\n",
    "    \"Data Integration\", \"Industrial Automation\", \"Lead Generation\", \"Casino\", \"Wearables\",\n",
    "    \"SaaS\", \"Coffee\", \"Optical Communication\", \"Advertising Platforms\", \"Transaction Processing\",\n",
    "    \"Emergency Medicine\", \"Clinical Trials\", \"Software Engineering\", \"Animation\",\n",
    "    \"Communication Hardware\", \"Productivity Tools\", \"Food Processing\", \"Agriculture\",\n",
    "    \"Geospatial\", \"Web Development\", \"Infrastructure\", \"Podcast\", \"Marketing\", \"Winery\",\n",
    "    \"Social Media Management\", \"Life Science\", \"Consulting\", \"Network Hardware\",\n",
    "    \"Virtualization\", \"Small and Medium Businesses\", \"Hospitality\", \"Music\",\n",
    "    \"Video Conferencing\", \"Tourism\", \"Public Transportation\", \"Space Travel\", \"Furniture\",\n",
    "    \"Online Auctions\", \"Messaging\", \"Social News\", \"Mobile Apps\", \"Event Promotion\",\n",
    "    \"Photography\", \"Intellectual Property\", \"Waste Management\", \"Big Data\", \"Hospital\",\n",
    "    \"Commercial Lending\", \"Home Health Care\", \"STEM Education\", \"Bioinformatics\",\n",
    "    \"E-Learning\", \"Events\", \"Non Profit\", \"Software\", \"Last Mile Transportation\",\n",
    "    \"Cosmetics\", \"Auto Insurance\", \"Content\", \"Location Based Services\", \"Lifestyle\",\n",
    "    \"Commercial Real Estate\", \"Industrial Manufacturing\", \"Vertical Search\", \"AdTech\",\n",
    "    \"B2B\", \"Developer Tools\", \"3D Technology\", \"Network Security\", \"Cycling\",\n",
    "    \"Computer Vision\", \"Classifieds\", \"Industrial Engineering\", \"Cyber Security\",\n",
    "    \"Biometrics\", \"Audio\", \"Freelance\", \"Sensor\", \"Climate Tech\", \"Home and Garden\",\n",
    "    \"Health Diagnostics\", \"Machinery Manufacturing\", \"Crowdfunding\", \"eSports\", \"Shoes\",\n",
    "    \"RFID\", \"Debit Cards\", \"Artificial Intelligence\", \"Robotics\", \"Dating\", \"Health Insurance\",\n",
    "    \"Mobile\", \"Recycling\", \"Leisure\", \"Private Cloud\", \"Marketplace\", \"Journalism\",\n",
    "    \"Hydroponics\", \"Media and Entertainment\", \"Enterprise\", \"Jewelry\", \"Electric Vehicle\",\n",
    "    \"GPU\", \"Risk Management\", \"Advanced Materials\", \"Product Research\", \"Mechanical Engineering\",\n",
    "    \"Banking\", \"Digital Signage\", \"Real Time\", \"AgTech\", \"Loyalty Programs\", \"B2G\", \"Coworking\",\n",
    "    \"Mapping Services\", \"Intelligent Systems\", \"Personal Health\", \"Nanotechnology\",\n",
    "    \"E-Signature\", \"Social Media Marketing\", \"PaaS\", \"IT Infrastructure\", \"Social Network\",\n",
    "    \"Cloud Security\", \"Tobacco\", \"National Security\", \"E-Commerce\", \"mHealth\", \"Shipping\",\n",
    "    \"Fertility\", \"Management Consulting\", \"Genetics\", \"Compliance\", \"Oncology\", \"Retail\",\n",
    "    \"Food and Beverage\", \"Project Management\", \"Civil Engineering\", \"Open Source\", \"Procurement\",\n",
    "    \"Cloud Storage\", \"Medical\", \"Database\", \"Hardware\", \"Home Decor\", \"Commercial\",\n",
    "    \"Data Visualization\", \"Electrical Distribution\", \"Manufacturing\", \"Battery\", \"Logistics\",\n",
    "    \"Beauty\", \"Content Marketing\", \"PC Games\", \"Children\", \"AudioTech\", \"CRM\",\n",
    "    \"Natural Language Processing\", \"Therapeutics\", \"Point of Sale\", \"Neuroscience\", \"NFC\",\n",
    "    \"Blockchain\", \"3D Printing\", \"Smart Home\", \"Life Insurance\", \"Stock Exchanges\",\n",
    "    \"Transportation\", \"Bitcoin\", \"Business Information Systems\", \"Snack Food\", \"FinTech\",\n",
    "    \"Travel Accommodations\", \"Energy Efficiency\", \"Mobile Devices\", \"Air Transportation\",\n",
    "    \"Business Intelligence\", \"Q&A\", \"Supply Chain Management\", \"Billing\", \"Farming\", \"Pet\",\n",
    "    \"Energy Management\", \"Electronic Health Record (EHR)\", \"Cloud Data Services\", \"Fuel\",\n",
    "    \"Unified Communications\", \"Energy Storage\", \"FoodTech\", \"Search Engine\", \"Biopharma\",\n",
    "    \"Financial Exchanges\", \"VoIP\", \"News\", \"Console Games\", \"Simulation\", \"Human Resources\",\n",
    "    \"Environmental Engineering\", \"Alternative Medicine\"\n",
    "]\n",
    "\n",
    "\n",
    "# Functions\n",
    "functions = [\n",
    "    \"Product Management\",\n",
    "    \"Marketing\",\n",
    "    \"Sales\",\n",
    "    \"Engineering\",\n",
    "    \"Human Resources\",\n",
    "    \"Finance\",\n",
    "    \"Operations\",\n",
    "    \"Customer Support\",\n",
    "    \"Research & Development\",\n",
    "    \"Legal\"\n",
    "]\n",
    "\n",
    "# Skills\n",
    "skills = [\n",
    "    \"Product Design\",\n",
    "    \"Software Development\",\n",
    "    \"Data Analysis\",\n",
    "    \"Project Management\",\n",
    "    \"Digital Marketing\",\n",
    "    \"Graphic Design\",\n",
    "    \"Financial Analysis\",\n",
    "    \"Leadership\",\n",
    "    \"Communication\",\n",
    "    \"Problem Solving\"\n",
    "]\n",
    "\n",
    "# Experience\n",
    "experience = [\n",
    "    \"Hyper Growth\",\n",
    "    \"Turnaround\",\n",
    "    \"Startup Experience\",\n",
    "    \"Leadership Experience\",\n",
    "    \"Cross-functional Experience\",\n",
    "    \"Remote Work Experience\",\n",
    "    \"International Experience\",\n",
    "    \"Industry-specific Experience\",\n",
    "    \"Entrepreneurial Experience\",\n",
    "    \"Consulting Experience\"\n",
    "]\n",
    "\n",
    "# Revenue Scale\n",
    "revenue_scale = [\n",
    "    \"$0-10M\",\n",
    "    \"$10-25M\",\n",
    "    \"$25-50M\",\n",
    "    \"$50-100M\",\n",
    "    \"$100-500M\",\n",
    "    \"$500M-1B\",\n",
    "    \"$1-10B\",\n",
    "    \"$10-50B\",\n",
    "    \"$50-100B\",\n",
    "    \"Over $100B\"\n",
    "]\n",
    "\n",
    "# Funding Rounds\n",
    "# List of funding rounds\n",
    "funding_rounds = ['Stake Purchase', 'Series C', 'Series G', 'Series B', 'Series Unknown', 'Undisclosed', 'Initial Coin Offering', 'Venture', 'Debt Financing', 'Post-IPO Secondary', 'Going Private', 'Non-Equity Assistance', 'Merger', 'Series H', 'Series E', 'Series I', 'Series D', 'Joint Venture', 'Convertible Note', 'Secondary Market', 'Pipe', 'Post-IPO Debt', 'Equity Crowdfunding', 'Seed', 'Buyout (LBO, MBO, MBI)', 'Recapitalization', 'Series A', 'Growth Capital', 'Consolidation', 'Grant', 'Angel', 'Series F', 'Acquisition Financing', 'Corporate Round', 'Product Crowdfunding', 'Post-IPO Equity', 'Divestiture', 'Secondary Buyout', 'Series J', 'Pre-Seed', 'Private Equity', 'Special Situations/Distressed', 'Add-On Acquisition']\n",
    "\n",
    "\n",
    "print(f\"funding_rounds no-> {len(funding_rounds)}\")\n",
    "print(f\"sector no-> {len(sectors)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ea3a7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domains: B2B, B2C, E-commerce, Healthcare, Technology, Finance, Education, Real Estate, Hospitality, Automotive, sectors: Personal Finance, Virtual Reality, Eyewear, Franchise, Cloud Infrastructure, DSP, Internet of Things, Drones, Digital Marketing, Fuel Cell, Health Care, Product Management, Water, Credit Cards, Education, Wellness, Broadcasting, Visual Search, Navigation, Film Production, Music Streaming, Home Improvement, Sporting Goods, Collaboration, Sales, Wine And Spirits, Semiconductor, Ticketing, Service Industry, Casual Games, Bakery, Ethereum, Fantasy Sports, Gaming, Real Estate Investment, Tea, Concerts, Speech Recognition, Enterprise Applications, Pharmaceutical, TV, Wireless, B2C, E-Commerce Platforms, Cloud Management, Data Storage, Innovation Management, Art, Video Streaming, Apps, Video, Management Information Systems, Information Services, Web Design, Organic, Retail Technology, EdTech, Operating Systems, Insurance, Food Delivery, Employee Benefits, SEO, Financial Services, Parks, Payments, Security, Satellite Communication, Fashion, Chemical, HRTech, Brand Marketing, Consumer Electronics, Energy, Mobile Payments, Machine Learning, Incubators, Public Safety, Data Center, Foundries, Consumer Research, Residential, Natural Resources, Content Creators, Made to Order, Consumer Goods, Wealth Management, Medical Device, CivicTech, Resorts, Image Recognition, Sports, Reservations, Consumer Lending, Car Sharing, Cloud Computing, Trading Platform, Developer Platform, Business Development, Test and Measurement, Autonomous Vehicles, Plastics and Rubber Manufacturing, Career Planning, Data Center Automation, Peer to Peer, Renewable Energy, Information Technology, Property Management, IT Management, Marketing Automation, Government, Fossil Fuels, Mining, Application Performance Management, Baby, Subscription Service, Mining Technology, Publishing, Building Maintenance, Oil and Gas, Motion Capture, Property Development, Travel, Mobility Tech, Finance, Enterprise Software, GovTech, Impact Investing, Ad Network, Diabetes, Social Media Advertising, Real Estate, CAD, Internet, Product Design, Amusement Park and Arcade, Solar, Indoor Positioning, Fortune-500, Wind Energy, Product Search, Semantic Search, Delivery, Internet Radio, Construction Technology, Email, Printing, Price Comparison, Racing, Grocery, Vacation Rental, Cryptocurrency, Ride Sharing, Public Relations, Electronics, Video Games, Organic Food, Embedded Systems, Self-Storage, ISP, Property Insurance, Craft Beer, Text Analytics, Collaborative Consumption, Market Research, Online Portals, Venture Capital Firms, Family, Digital Media, Recruiting, Fitness, Predictive Analytics, Call Center, Web Hosting, Professional Services, Outsourcing, Consumer, Corporate Training, Rental, Graphic Design, SMS, Aerospace, Direct Marketing, Social Bookmarking, Packaging Services, Advertising, Clean Energy, HealthTech, Communities, Nutrition, Outpatient Care, Social Media, Fraud Detection, Online Games, Real Estate Tech, File Sharing, CleanTech, Domain Registrar, Leasing, Guides, Brewing, Social, Green Consumer Goods, Film, Gambling, Crowdsourcing, Sustainability, Recreational Vehicles, Industrial Design, Shopping, Lending, Asset Management, Automotive, Developer APIs, Nuclear, Building Material, Smart Building, Employment, Mineral, Retirement, Industrial, Construction, Photo Editing, Communications Infrastructure, Psychology, Customer Service, Dental, Auctions, Private Equity Firms, Credit, Marketing Tech, Content Discovery, Chemical Engineering, Technical Support, Biotechnology, Hotel, Delivery Service, Computer, Precious Metals, InsurTech, Video Advertising, Animal Feed, Analytics, Legal, Supply Chain Technology, Tutoring, Augmented Reality, Digital Entertainment, Dietary Supplements, GreenTech, Venture Capital, Flash Storage, Language Learning, Laser, Telecommunications, Training, Home Services, Direct Sales, Identity Management, Content Delivery Network, Restaurant Tech, Ad Targeting, Blogging Platforms, Restaurants, Task Management, Cannabis, Knowledge Management, Data Integration, Industrial Automation, Lead Generation, Casino, Wearables, SaaS, Coffee, Optical Communication, Advertising Platforms, Transaction Processing, Emergency Medicine, Clinical Trials, Software Engineering, Animation, Communication Hardware, Productivity Tools, Food Processing, Agriculture, Geospatial, Web Development, Infrastructure, Podcast, Marketing, Winery, Social Media Management, Life Science, Consulting, Network Hardware, Virtualization, Small and Medium Businesses, Hospitality, Music, Video Conferencing, Tourism, Public Transportation, Space Travel, Furniture, Online Auctions, Messaging, Social News, Mobile Apps, Event Promotion, Photography, Intellectual Property, Waste Management, Big Data, Hospital, Commercial Lending, Home Health Care, STEM Education, Bioinformatics, E-Learning, Events, Non Profit, Software, Last Mile Transportation, Cosmetics, Auto Insurance, Content, Location Based Services, Lifestyle, Commercial Real Estate, Industrial Manufacturing, Vertical Search, AdTech, B2B, Developer Tools, 3D Technology, Network Security, Cycling, Computer Vision, Classifieds, Industrial Engineering, Cyber Security, Biometrics, Audio, Freelance, Sensor, Climate Tech, Home and Garden, Health Diagnostics, Machinery Manufacturing, Crowdfunding, eSports, Shoes, RFID, Debit Cards, Artificial Intelligence, Robotics, Dating, Health Insurance, Mobile, Recycling, Leisure, Private Cloud, Marketplace, Journalism, Hydroponics, Media and Entertainment, Enterprise, Jewelry, Electric Vehicle, GPU, Risk Management, Advanced Materials, Product Research, Mechanical Engineering, Banking, Digital Signage, Real Time, AgTech, Loyalty Programs, B2G, Coworking, Mapping Services, Intelligent Systems, Personal Health, Nanotechnology, E-Signature, Social Media Marketing, PaaS, IT Infrastructure, Social Network, Cloud Security, Tobacco, National Security, E-Commerce, mHealth, Shipping, Fertility, Management Consulting, Genetics, Compliance, Oncology, Retail, Food and Beverage, Project Management, Civil Engineering, Open Source, Procurement, Cloud Storage, Medical, Database, Hardware, Home Decor, Commercial, Data Visualization, Electrical Distribution, Manufacturing, Battery, Logistics, Beauty, Content Marketing, PC Games, Children, AudioTech, CRM, Natural Language Processing, Therapeutics, Point of Sale, Neuroscience, NFC, Blockchain, 3D Printing, Smart Home, Life Insurance, Stock Exchanges, Transportation, Bitcoin, Business Information Systems, Snack Food, FinTech, Travel Accommodations, Energy Efficiency, Mobile Devices, Air Transportation, Business Intelligence, Q&A, Supply Chain Management, Billing, Farming, Pet, Energy Management, Electronic Health Record (EHR), Cloud Data Services, Fuel, Unified Communications, Energy Storage, FoodTech, Search Engine, Biopharma, Financial Exchanges, VoIP, News, Console Games, Simulation, Human Resources, Environmental Engineering, Alternative Medicine, functions: Product Management, Marketing, Sales, Engineering, Human Resources, Finance, Operations, Customer Support, Research & Development, Legal, skills: Product Design, Software Development, Data Analysis, Project Management, Digital Marketing, Graphic Design, Financial Analysis, Leadership, Communication, Problem Solving, experience: Hyper Growth, Turnaround, Startup Experience, Leadership Experience, Cross-functional Experience, Remote Work Experience, International Experience, Industry-specific Experience, Entrepreneurial Experience, Consulting Experience, revenue_scale: $0-10M, $10-25M, $25-50M, $50-100M, $100-500M, $500M-1B, $1-10B, $10-50B, $50-100B, Over $100B, funding_rounds: Stake Purchase, Series C, Series G, Series B, Series Unknown, Undisclosed, Initial Coin Offering, Venture, Debt Financing, Post-IPO Secondary, Going Private, Non-Equity Assistance, Merger, Series H, Series E, Series I, Series D, Joint Venture, Convertible Note, Secondary Market, Pipe, Post-IPO Debt, Equity Crowdfunding, Seed, Buyout (LBO, MBO, MBI), Recapitalization, Series A, Growth Capital, Consolidation, Grant, Angel, Series F, Acquisition Financing, Corporate Round, Product Crowdfunding, Post-IPO Equity, Divestiture, Secondary Buyout, Series J, Pre-Seed, Private Equity, Special Situations/Distressed, Add-On Acquisition\n"
     ]
    }
   ],
   "source": [
    "# Combine all lists into a single string with names\n",
    "combined_tag_string = \"domains: \" + \", \".join(domains) + \", \" \\\n",
    "                + \"sectors: \" + \", \".join(sectors) + \", \" \\\n",
    "                + \"functions: \" + \", \".join(functions) + \", \" \\\n",
    "                + \"skills: \" + \", \".join(skills) + \", \" \\\n",
    "                + \"experience: \" + \", \".join(experience) + \", \" \\\n",
    "                + \"revenue_scale: \" + \", \".join(revenue_scale) + \", \" \\\n",
    "                + \"funding_rounds: \" + \", \".join(funding_rounds)\n",
    "\n",
    "print(combined_tag_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a3e3508-e254-4a59-b65c-848e232044ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AWS_ACCESS_KEY_ID =\"ASIAS6ZGJXEKM4LUUBTX\"\n",
    "AWS_SECRET_ACCESS_KEY = \"Jxgha1M87ba/gq9f8R2e9pHDwEf7XWvMzB7W5jpl\"\n",
    "AWS_SESSION_TOKEN = \"IQoJb3JpZ2luX2VjEEcaCXVzLWVhc3QtMSJGMEQCIHIwKkTfEeKPlm1g5c5uJsLX8wp/TTnSwEYx1wf6vtRTAiBlCpKBSt94NOSxawin2JQ1W9lk5+nQTo252vMj3rMjwyqDAwif//////////8BEAQaDDIwMzU1NDQwNDYyOCIMadD7I+W02cAALdMfKtcCWnu7wnb6FK5jU1mFWlCn5LKyDoZ18MXz9KT0+pRwMc+L+ge1XDZlAnn8a89mfCfE0UGsgZELLjh3YT/Xz/Bk2LVG0OjJ8CGKe1sxFIABsti37biOwojU3xH2Mg9bD/uS0BGnQ9jMlNbvmrLXykPDWOjsi9Ps0uOzEurdO8eWTqbmfbsnZL9E3qoDejFh4OV4JAYv8upvygeVorzG4eLJuJYo0S+eDfz/QBPw1uOO5zbLH6daBqmexMYuyHGfyWCO5A0lYJm2ZF8E3hla0dXFgxHc9XegPYqISydrVEFFNuODbQk+/CsArXyAm70iIRL1wOqFd9bOWCFuyeB5x8tOwlZQdLI0ZmGvHpMzcGrBjOwB5W6XJB7/S1a99lkWnTzdbermgzUpGzWvI2oYMAtSqCSLhpDn58iY9B2x+lmoT/B/JtTUp9673L/dTk9HzcG7kcLDeOk8YTDyx9yxBjqoAd1tS+wO6K/yoHN2OP1+Ujwi8+/3O6AoPeeRSW2trRA+keGyZCM+LLzajg2s0JQoZPOBT9FmMHrfIhwHvi79r4O2aAZgnO5tGgu67hvTeazu7zzTbNv/AQyk4WT0oFEnJyI7DMQhSTt1GQ/1pizYSHwQPbcupwDcLA48FXATDIfvhNGQzHF7MAIf/OyIo1H7TE867f7PgODXDwLQjnehjWzyRBwHET9DBw==\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d6db3c4-41a6-42d7-a4cb-0ed30eab494a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Now json_data contains the JSON data read from the file \\nwith open(\\'final_output/person_final_output.json\\', \\'r\\') as f:\\n    file_content = f.read()\\n\\nprint(file_content)\\nprint(\"File size:\", len(file_content))'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import json\n",
    "\n",
    "# Assuming json_df is your data\n",
    "with open('final_output/person_final_output.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "    \n",
    "'''\n",
    "'''# Now json_data contains the JSON data read from the file \n",
    "with open('final_output/person_final_output.json', 'r') as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "print(file_content)\n",
    "print(\"File size:\", len(file_content))'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83c32bd8-f720-42fb-bd9f-ceff27af9a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Convert JSON data to DataFrame\\njson_df = spark.read.json(spark.sparkContext.parallelize(json_data))\\n\\n# Show DataFrame\\njson_df.show(5,truncate=False)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Convert JSON data to DataFrame\n",
    "json_df = spark.read.json(spark.sparkContext.parallelize(json_data))\n",
    "\n",
    "# Show DataFrame\n",
    "json_df.show(5,truncate=False)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f4b66b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the parquet file and create a new DataFrame\n",
    "#final_df = spark.read.parquet(\"final_output/df2.parquet\")\n",
    "#final_df = spark.read.parquet(\"final_output/df3.parquet\")\n",
    "final_df = spark.read.parquet(\"final_output/df4.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27cc74c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 999\n",
      "+---------+--------------+-------+----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+----------------------+-----------+---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------+\n",
      "|person_id|name          |address|headline                                |description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |created_at               |updated_at            |customer_id|education|employments                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |urls                                                   |\n",
      "+---------+--------------+-------+----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+----------------------+-----------+---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------+\n",
      "|867291105|Tendeka Matatu|       |Director of Local language Films, Africa|Tendeka joined Netflix as the Director of Film in Africa in 2021 following a lengthy career as a filmmaker and producer in Africa and beyond.. In his current role, Tendeka is charged with leading the creation of original films from the Sub-Saharan region. His career in storytelling began in the mid-'90s as a producer, working on high-end commercials and music videos with renowned film director Tony Kaye.\\n\\nIn 2001, Tendeka moved to South Africa to join DV8 Films, where he was involved in the successful production and financing of a slate of local features and numerous co-productions, including Richard E Grant's Wah Wah. In 2009 Tendeka set up his production company Ten10 Films which focused on collaborating with black filmmaking talent to create diversity-driven film & TV content for a global market. With offices in Johannesburg and London, the company's slate included projects for AMC Studios, Sony Pictures Television, Netflix and Fremantle.\\n\\nAs a producer, Tendeka’s credits include the multi-award-winning Max & Mona and Abyss Boys; the South African box office hits Material and Crazy Monkey; and the action-drama epic Gangster's Paradise: Jerusalema, which was South Africa's official entry for the Academy Awards Foreign Language. Some of Tendeka's films have premiered at major film festivals, including Berlin, Toronto, Rotterdam, Busan, and London. Other credits include Cold Harbour, Tiger House, and Freedom. Tendeka is an alumnus of the prestigious film industry business and leadership course, Inside Pictures, and a member of the producer's branch of The Academy of Motion Picture Arts & Sciences.\\n\\nProducer Filmography:\\nhttp://www.imdb.com/name/nm1568121/|2023-12-11 06:18:08.13904|2023-10-26 15:57:22.35|NULL       |NULL     |[{NULL, NULL, NULL, Producer, 2004-04-01, 2007-10-01, NULL, NULL, NULL, NULL, NULL, NULL}, {NULL, NULL, NULL, Producer, 2002-09-01, 2004-04-01, NULL, NULL, NULL, NULL, NULL, NULL}, {NULL, NULL, Director, Founder/Managing Director, 2008-01-01, 2021-07-01, NULL, NULL, NULL, NULL, NULL, NULL}, {NULL, NULL, NULL, Co Founder, 2014-05-01, 2018-01-01, NULL, NULL, NULL, NULL, NULL, NULL}, {2289, Netflix, Director, Director of Local language Films, Africa, 2021-09-01, NULL, 8772810300.00, 15635, NFLX, Post-IPO Debt, NULL, Saul Bisht}]|[{linkedin, https://www.linkedin.com/in/tendekamatatu}]|\n",
      "+---------+--------------+-------+----------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+----------------------+-----------+---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "record_count = final_df.count()\n",
    "print(\"Total number of records:\", record_count)\n",
    "final_df.show(1,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05cb0cb8-17f2-4b71-b98a-2083cda166fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- person_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- headline: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- created_at: timestamp (nullable = true)\n",
      " |-- updated_at: timestamp (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- education: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- institution_id: long (nullable = true)\n",
      " |    |    |-- institution_name: string (nullable = true)\n",
      " |    |    |-- degree: string (nullable = true)\n",
      " |    |    |-- subject: string (nullable = true)\n",
      " |    |    |-- started_on: date (nullable = true)\n",
      " |    |    |-- ended_on: date (nullable = true)\n",
      " |-- employments: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- company_id: long (nullable = true)\n",
      " |    |    |-- company_name: string (nullable = true)\n",
      " |    |    |-- seniority_level: string (nullable = true)\n",
      " |    |    |-- title: string (nullable = true)\n",
      " |    |    |-- started_on: date (nullable = true)\n",
      " |    |    |-- ended_on: date (nullable = true)\n",
      " |    |    |-- amount_usd: decimal(20,2) (nullable = true)\n",
      " |    |    |-- headcount: long (nullable = true)\n",
      " |    |    |-- stock_ticker: string (nullable = true)\n",
      " |    |    |-- funding_name: string (nullable = true)\n",
      " |    |    |-- investor_company_id: long (nullable = true)\n",
      " |    |    |-- investor: string (nullable = true)\n",
      " |-- urls: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- url_type: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "11f85d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F \n",
    "# Create an empty list to store the column expressions\n",
    "column_exprs = []\n",
    "\n",
    "# For each column in the DataFrame\n",
    "for col_name in final_df.columns:\n",
    "    # Create a new column expression that concatenates the column name and the column value\n",
    "    column_exprs.append(F.concat(F.lit(col_name + \":\"), final_df[col_name].cast(\"string\")))\n",
    "\n",
    "# Concatenate all column expressions into one single column 'single_text'\n",
    "single_file_for_each_person_df = final_df.select(F.concat_ws(' ', *column_exprs).alias('single_file_for_each_person'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b7ace762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|single_file_for_each_person                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|person_id:867291105 name:Tendeka Matatu address: headline:Director of Local language Films, Africa description:Tendeka joined Netflix as the Director of Film in Africa in 2021 following a lengthy career as a filmmaker and producer in Africa and beyond.. In his current role, Tendeka is charged with leading the creation of original films from the Sub-Saharan region. His career in storytelling began in the mid-'90s as a producer, working on high-end commercials and music videos with renowned film director Tony Kaye.\\n\\nIn 2001, Tendeka moved to South Africa to join DV8 Films, where he was involved in the successful production and financing of a slate of local features and numerous co-productions, including Richard E Grant's Wah Wah. In 2009 Tendeka set up his production company Ten10 Films which focused on collaborating with black filmmaking talent to create diversity-driven film & TV content for a global market. With offices in Johannesburg and London, the company's slate included projects for AMC Studios, Sony Pictures Television, Netflix and Fremantle.\\n\\nAs a producer, Tendeka’s credits include the multi-award-winning Max & Mona and Abyss Boys; the South African box office hits Material and Crazy Monkey; and the action-drama epic Gangster's Paradise: Jerusalema, which was South Africa's official entry for the Academy Awards Foreign Language. Some of Tendeka's films have premiered at major film festivals, including Berlin, Toronto, Rotterdam, Busan, and London. Other credits include Cold Harbour, Tiger House, and Freedom. Tendeka is an alumnus of the prestigious film industry business and leadership course, Inside Pictures, and a member of the producer's branch of The Academy of Motion Picture Arts & Sciences.\\n\\nProducer Filmography:\\nhttp://www.imdb.com/name/nm1568121/ created_at:2023-12-11 06:18:08.13904 updated_at:2023-10-26 15:57:22.35 employments:[{null, null, null, Producer, 2004-04-01, 2007-10-01, null, null, null}, {null, null, null, Producer, 2002-09-01, 2004-04-01, null, null, null}, {null, null, Director, Founder/Managing Director, 2008-01-01, 2021-07-01, null, null, null}, {null, null, null, Co Founder, 2014-05-01, 2018-01-01, null, null, null}, {2289, Netflix, Director, Director of Local language Films, Africa, 2021-09-01, null, 8772810300.00, 15635, NFLX}] urls:[{linkedin, https://www.linkedin.com/in/tendekamatatu}]|\n",
      "|person_id:109796082 name:Joshua Limp address:Wheaton, Illinois, US headline:Manager, Oncology Market Access Insights at AbbVie description:I am a consumer insights professional with a foundation in analytics brought through experience with both syndicated data and primary research data. My interests and background lie primarily in the CPG industry, related to brand marketing and strategy. In addition, I have extensive involvement in the healthcare industry, specifically project management among the life sciences.\\n\\nSpecialties: Category Management & Marketing Research\\n- Sustainable share growth\\n- Brand health and strategy\\n- Sales insights created_at:2023-12-11 06:18:08.13904 updated_at:2023-10-26 15:57:22.35 education:[{null, Lincoln - Way East High School, null, null, null, 2008-01-01}, {null, University Of Illinois At Chicago, Bachelors;Bachelor Of Science, Marketing, 2008-01-01, 2012-01-01}] employments:[{null, null, null, Market Research Assistant, 2010-05-01, 2010-12-01, null, null, null}, {26048, Ipsos, null, Client Service Intern, 2011-05-01, 2012-07-01, null, null, null}, {88002, PepsiCo, null, Category Management Analyst, 2013-09-01, 2016-03-01, null, null, null}, {113128, AbbVie, null, Manager I, Oncology Market Access Insights, 2022-07-01, null, 10603963036.00, 51174, ABBV}, {306464, Molson Coors, null, Associate Insights Manager, 2019-10-01, 2021-06-01, null, null, null}, {306464, Molson Coors, null, Associate Manager, Portfolio Strategy, 2021-06-01, 2022-01-01, null, null, null}, {306464, Molson Coors, null, Manager, Precision Marketing Analytics & Optimization, 2022-01-01, 2022-07-01, null, null, null}, {342039, Center of Healthcare Innovation, null, Senior Project Manager, 2009-09-01, 2019-05-01, null, null, null}, {342039, Center of Healthcare Innovation, Director, Volunteer: Director Of Business Development, 2019-05-01, null, null, null, null}, {842562, August Storck KG, null, Associate Insights Manager, 2016-03-01, 2019-10-01, null, null, null}, {8418321, Ipsos Marketing Us, Director, Project Director, 2012-07-01, 2013-09-01, null, null, null}] urls:[{linkedin, https://www.linkedin.com/in/joshualimp}, {facebook, facebook.com/josh.limp.5}]                                                                                                                                                                              |\n",
      "|person_id:949256266 name:Vivian Weng address:SINGAPORE headline:Product Design, Strategy & Managment created_at:2023-12-11 06:18:08.13904 customer_id:7538cb11-1c23-4c76-87c7-5111a0f166dc education:[{null, University of California, Berkeley - Walter A. Haas School of Business, null, MBA, Finance, 2007-01-01, 2009-01-01}, {null, National Taiwan University, null, BA, International Relations, 1998-01-01, 2002-01-01}, {null, Yale University, null, MA, International Developmental Economics, 2002-01-01, 2003-01-01}] employments:[{59, Goldman Sachs, null, Investment Banking Division Summer Associate, 2008-06-01, 2008-08-01, 8417546311.00, 75859, GS}, {1660, Apple, null, Product Design Producer, International Product Design, 2019-04-01, null, 31949031445.00, 224704, AAPL}, {4007, McKinsey & Company, null, Business Analyst, 2004-01-01, 2007-01-01, null, null, null}, {4007, McKinsey & Company, null, Senior Associate, Corporate Finance, 2009-09-01, 2011-11-01, null, null, null}, {15861, DBS Bank, VP, Vice President, Innovation Group, 2016-07-01, 2019-04-01, null, null, null}, {7962172, Frog, Director, Associate Strategy Director, Innovation Strategy Group, 2012-02-01, 2016-06-01, null, null, null}] urls:[{linkedin, https://www.linkedin.com/in/vivian-weng-4a0b884}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, 'df_single_text' is a DataFrame where each row is a single text string\n",
    "single_file_for_each_person_df.show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "495d183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|single_file_for_each_person                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|person_id:867291105 name:Tendeka Matatu address: headline:Director of Local language Films, Africa description:Tendeka joined Netflix as the Director of Film in Africa in 2021 following a lengthy career as a filmmaker and producer in Africa and beyond.. In his current role, Tendeka is charged with leading the creation of original films from the Sub-Saharan region. His career in storytelling began in the mid-'90s as a producer, working on high-end commercials and music videos with renowned film director Tony Kaye.\\n\\nIn 2001, Tendeka moved to South Africa to join DV8 Films, where he was involved in the successful production and financing of a slate of local features and numerous co-productions, including Richard E Grant's Wah Wah. In 2009 Tendeka set up his production company Ten10 Films which focused on collaborating with black filmmaking talent to create diversity-driven film & TV content for a global market. With offices in Johannesburg and London, the company's slate included projects for AMC Studios, Sony Pictures Television, Netflix and Fremantle.\\n\\nAs a producer, Tendeka’s credits include the multi-award-winning Max & Mona and Abyss Boys; the South African box office hits Material and Crazy Monkey; and the action-drama epic Gangster's Paradise: Jerusalema, which was South Africa's official entry for the Academy Awards Foreign Language. Some of Tendeka's films have premiered at major film festivals, including Berlin, Toronto, Rotterdam, Busan, and London. Other credits include Cold Harbour, Tiger House, and Freedom. Tendeka is an alumnus of the prestigious film industry business and leadership course, Inside Pictures, and a member of the producer's branch of The Academy of Motion Picture Arts & Sciences.\\n\\nProducer Filmography:\\nhttp://www.imdb.com/name/nm1568121/ created_at:2023-12-11 06:18:08.13904 updated_at:2023-10-26 15:57:22.35 employments:[{null, null, null, Producer, 2004-04-01, 2007-10-01, null, null, null}, {null, null, null, Producer, 2002-09-01, 2004-04-01, null, null, null}, {null, null, Director, Founder/Managing Director, 2008-01-01, 2021-07-01, null, null, null}, {null, null, null, Co Founder, 2014-05-01, 2018-01-01, null, null, null}, {2289, Netflix, Director, Director of Local language Films, Africa, 2021-09-01, null, 8772810300.00, 15635, NFLX}] urls:[{linkedin, https://www.linkedin.com/in/tendekamatatu}]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "First row as a string: {'single_file_for_each_person': 'person_id:26336563 name:Michael Stephens address:Los Angeles County, California, US created_at:2023-12-11 06:18:08.13904 updated_at:2023-10-19 07:24:05.526666 education:[{null, California State University, Northridge, Bachelor Of Applied Science;Bachelors, Public Health, 2004-01-01, 2009-01-01}] employments:[{110721, Berkshire Hathaway, null, Real Estate Agent, 2018-01-01, null, 582237200.00, null, BRKB}, {934791, eSOL, Director, Director, 1999-05-01, null, null, null, null}] urls:[{linkedin, https://www.linkedin.com/in/michael-stephens-2950a27a}]'}\n"
     ]
    }
   ],
   "source": [
    "# Assuming single_file_for_each_person_df is your DataFrame\n",
    "# Show the DataFrame without truncating\n",
    "single_file_for_each_person_df.show(1,truncate=False)\n",
    "\n",
    "# Convert DataFrame to a list of rows\n",
    "rows = single_file_for_each_person_df.collect()\n",
    "\n",
    "# Check if there are any rows\n",
    "if rows:\n",
    "    # Extract the first row\n",
    "    first_row = rows[104]\n",
    "\n",
    "    # Convert the first row to a string\n",
    "    first_row_string = str(first_row.asDict())\n",
    "\n",
    "    # Print the first row as a string\n",
    "    print(\"First row as a string:\", first_row_string)\n",
    "else:\n",
    "    print(\"DataFrame is empty\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532023f-cecf-4dca-80e6-74f6b3a97682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a503c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def generate_response(model_id, prompt,maxGenLen,topp,temp):\n",
    "   \n",
    "    payload = json.dumps({\n",
    "        'prompt': prompt,\n",
    "        'max_gen_len': maxGenLen,\n",
    "        'top_p': topp,\n",
    "        'temperature': temp\n",
    "    })\n",
    "\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id= AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key= AWS_SECRET_ACCESS_KEY,\n",
    "        aws_session_token=AWS_SESSION_TOKEN\n",
    "    )  \n",
    "\n",
    "    bedrock_runtime = session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=payload,\n",
    "        modelId=model_id,\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    response_text = response_body['generation']\n",
    "\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7bb3eb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m      2\u001b[0m llamaModelId \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta.llama2-13b-chat-v1\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m----> 3\u001b[0m choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDomain-1,sector-2,Function-3,Skills-4,experience-5,revenue_scale-6 ,funding-7\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      6\u001b[0m    x \u001b[38;5;241m=\u001b[39m domains\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    " # Example usage\n",
    "llamaModelId = 'meta.llama2-13b-chat-v1' \n",
    "choice = input(\"Domain-1,sector-2,Function-3,Skills-4,experience-5,revenue_scale-6 ,funding-7\")\n",
    "\n",
    "if choice == '1':\n",
    "    x = domains\n",
    "    list_string = 'domains'\n",
    "elif choice == '2':\n",
    "    x = sectors\n",
    "    list_string = 'sectors'\n",
    "elif choice == '3':\n",
    "    x = functions\n",
    "    list_string = 'functions'\n",
    "elif choice == '4':\n",
    "    x = skills\n",
    "    list_string = 'skills'\n",
    "elif choice == '5':\n",
    "    x = experience\n",
    "    list_string = 'experience'\n",
    "elif choice == '6':\n",
    "    x = revenue_scale\n",
    "    list_string = 'revenue_scale'\n",
    "elif choice == '7':\n",
    "    x = funding_rounds\n",
    "    list_string = 'funding_rounds'\n",
    "else:\n",
    "    print(\"Invalid choice. Please enter 1 to 7.\")\n",
    "\n",
    "tag_string = \"x: \" + \", \".join(x)\n",
    "#prompt_string = (f \"please tag person profile\" + {first_row_string} + \" \"\n",
    " #                \"is he belongs to this\" +\" \" + {}+ \" \" + {tag_string} + \" \")\n",
    "\n",
    "prompt_string = (f\"from this person profile {first_row_string} \"\n",
    "                 f\"find is he belongs to this {list_string} Use Semantic search {tag_string} don't give any code\")\n",
    "\n",
    "# Print the first row string document\n",
    "print(\"prompt:\", prompt_string,\"\\n\")\n",
    "\n",
    "response_text = generate_response(llamaModelId, prompt_string,2048,0.9,0.2)\n",
    "print(f\"Model Response : {response_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7991f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad632f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: summarise this person profile  and is he belongs to this functions: Healthcare, Fintech, Retail, Manufacturing, Education, Energy, Transportation, Media & Entertainment, Telecommunications, Government {'single_file_for_each_person': 'person_id:56722060 name:Kelly Muchmore-Broz address:Omaha, Nebraska, US description:Annual Meeting Director at Berkshire Hathaway Inc. created_at:2023-12-11 06:18:08.13904 updated_at:2023-10-19 07:24:05.526666 education:[{null, University Of Tampa, null, Criminology, null, null}, {null, Mustang High School, null, null, null, null}] employments:[{110721, Berkshire Hathaway, Director, Annual Meeting Director, null, null, 582237200.00, null, BRKB}] urls:[{linkedin, https://www.linkedin.com/in/kelly-muchmore-broz-a99ab23}]'} \n",
      "\n",
      "\n",
      "\n",
      "This person profile belongs to the function of Healthcare, Fintech, Retail, Manufacturing, Education, Energy, Transportation, Media & Entertainment, Telecommunications, Government.\n",
      "\n",
      "The person's name is Kelly Muchmore-Broz, and they are the Annual Meeting Director at Berkshire Hathaway Inc. They have a background in Criminology from the University of Tampa, and they have worked at Mustang High School. They have one employment at Berkshire Hathaway as the Director of Annual Meeting. They have a LinkedIn profile with the URL https://www.linkedin.com/in/kelly-muchmore-broz-a99ab23.\n",
      "\n",
      "The person's education, employment, and skills are not specifically related to any of the functions you listed (Healthcare, Fintech, Retail, Manufacturing, Education, Energy, Transportation, Media & Entertainment, Telecommunications, Government). However, as the Annual Meeting Director at Berkshire Hathaway, they may have experience or knowledge that could be applicable to some of these functions.\n"
     ]
    }
   ],
   "source": [
    " # Example usage\n",
    "llamaModelId = 'meta.llama2-13b-chat-v1' \n",
    "\n",
    "functions_tag_string = \"functions: \" + \", \".join(sectors)\n",
    "prompt_string =  \"summarise this person profile \"+ \" \" + \"and\" + \" \" +\"is he belongs to this\" \\\n",
    "    \" \" + functions_tag_string + \" \" + first_row_string \n",
    "\n",
    "# Print the first row string document\n",
    "print(\"prompt:\", prompt_string,\"\\n\")\n",
    "\n",
    "response_text = generate_response(llamaModelId, prompt_string,2048,0.9,0.2)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Example usage\n",
    "llamaModelId = 'meta.llama2-13b-chat-v1' \n",
    "\n",
    "sector_tag_string = \"sectors: \" + \", \".join(sectors)\n",
    "prompt_string =  \"summarise this person profile \"+ \" \" + \"and\" + \" \" +\"is he belongs to this\" \\\n",
    "    \" \" + sector_tag_string+ \" \" + first_row_string \n",
    "\n",
    "# Print the first row string document\n",
    "print(\"prompt:\", prompt_string,\"\\n\")\n",
    "\n",
    "response_text = generate_response(llamaModelId, prompt_string,2048,0.9,0.2)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "334975bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 93\n",
      "+------------+--------------------+--------------------+-----+--------------------+-------------+-----------+-----------+----+------+-----------+---------+------------+---------------+-----------+--------------------+--------------------+----------+----------+----------+--------------------+--------------+--------------------+---------------------+---------------------+--------------------+---------------------+---------------------+--------------------+---------------------+---------------------+\n",
      "|person_id_pc|       created_at_pc|      customer_id_pc|id_pc|       updated_at_pc|person_id_ppl|       name|address_ppl|city|region|postal_code|  country|company_name|seniority_level|description|               title|            headline|started_on|  ended_on|company_id|      created_at_ppl|updated_at_ppl|           institute|latest_edu_created_at|latest_edu_updated_at|         employments|latest_emp_created_at|latest_emp_updated_at|                urls|latest_url_created_at|latest_url_updated_at|\n",
      "+------------+--------------------+--------------------+-----+--------------------+-------------+-----------+-----------+----+------+-----------+---------+------------+---------------+-----------+--------------------+--------------------+----------+----------+----------+--------------------+--------------+--------------------+---------------------+---------------------+--------------------+---------------------+---------------------+--------------------+---------------------+---------------------+\n",
      "|   949256266|2024-02-09 12:07:...|7538cb11-1c23-4c7...|   60|2024-02-09 12:07:...|    949256266|Vivian Weng|       NULL|NULL|  NULL|       NULL|SINGAPORE|    DBS Bank|             VP|       NULL|Vice President, I...|Product Design, S...|2016-07-01|2019-04-01|     15861|2023-12-11 06:18:...|          NULL|[{NULL, Universit...| 2023-12-11 06:18:...|                 NULL|[{15861, DBS Bank...| 2023-12-11 06:18:...|                 NULL|[{linkedin, https...| 2023-12-11 06:18:...|                 NULL|\n",
      "+------------+--------------------+--------------------+-----+--------------------+-------------+-----------+-----------+----+------+-----------+---------+------------+---------------+-----------+--------------------+--------------------+----------+----------+----------+--------------------+--------------+--------------------+---------------------+---------------------+--------------------+---------------------+---------------------+--------------------+---------------------+---------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' # Read the parquet file and create a new DataFrame\n",
    "new_df = spark.read.parquet(\"./df.parquet\")\n",
    "\n",
    "record_count = new_df.count()\n",
    "print(\"Total number of records:\", record_count)\n",
    "\n",
    "# Display a sample of rows\n",
    "new_df.show(1) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc2b883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|string_document                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|person_id_pc: 949256266, created_at_pc: 2024-02-09 12:07:56.872068, customer_id_pc: 7538cb11-1c23-4c76-87c7-5111a0f166dc, id_pc: 60, updated_at_pc: 2024-02-09 12:07:56.872068, person_id_ppl: 949256266, name: Vivian Weng, country: SINGAPORE, company_name: DBS Bank, seniority_level: VP, title: Vice President, Innovation Group, headline: Product Design, Strategy & Managment, started_on: 2016-07-01, ended_on: 2019-04-01, company_id: 15861, created_at_ppl: 2023-12-11 06:18:08.13904, institute: [{null, University of California, Berkeley - Walter A. Haas School of Business, null, MBA, Finance, 2007-01-01, 2009-01-01}, {null, National Taiwan University, null, BA, International Relations, 1998-01-01, 2002-01-01}, {null, Yale University, null, MA, International Developmental Economics, 2002-01-01, 2003-01-01}], latest_edu_created_at: 2023-12-11 06:18:37.445885, employments: [{15861, DBS Bank, VP, Vice President, Innovation Group, 2016-07-01, 2019-04-01}, {7962172, Frog, Director, Associate Strategy Director, Innovation Strategy Group, 2012-02-01, 2016-06-01}, {4007, McKinsey & Company, null, Business Analyst, 2004-01-01, 2007-01-01}, {4007, McKinsey & Company, null, Senior Associate, Corporate Finance, 2009-09-01, 2011-11-01}, {59, Goldman Sachs, null, Investment Banking Division Summer Associate, 2008-06-01, 2008-08-01}, {1660, Apple, null, Product Design Producer, International Product Design, 2019-04-01, null}], latest_emp_created_at: 2023-12-11 06:18:49.396966, urls: [{linkedin, https://www.linkedin.com/in/vivian-weng-4a0b884}], latest_url_created_at: 2023-12-11 06:18:57.46109|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat, lit,concat_ws,col\n",
    "\n",
    "# Create a list of column names\n",
    "columns = new_df.columns\n",
    "\n",
    "# Concatenate column names and values for each row\n",
    "string_documents_df = new_df.select(\n",
    "    concat_ws(\", \", *[concat(lit(column), lit(\": \"), col(column).cast(\"string\")) for column in columns]).alias(\"string_document\")\n",
    ")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "string_documents_df.show(1, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "725be81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 93\n",
      "Printing each row:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for row in string_documents_df.collect():\\n    #print( len(row.string_document))\\n    print(row.string_document)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows\n",
    "num_rows = string_documents_df.count()\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "# Iterate over each row and print\n",
    "print(\"Printing each row:\")\n",
    "'''for row in string_documents_df.collect():\n",
    "    #print( len(row.string_document))\n",
    "    print(row.string_document)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1583af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "def generate_response(model_id, prompt,maxGenLen,topp,temp):\n",
    "   \n",
    "    payload = json.dumps({\n",
    "        'prompt': prompt,\n",
    "        'max_gen_len': maxGenLen,\n",
    "        'top_p': topp,\n",
    "        'temperature': temp\n",
    "    })\n",
    "\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id= AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key= AWS_SECRET_ACCESS_KEY,\n",
    "        aws_session_token=AWS_SESSION_TOKEN\n",
    "    )  \n",
    "\n",
    "    bedrock_runtime = session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=payload,\n",
    "        modelId=model_id,\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    response_text = response_body['generation']\n",
    "\n",
    "    return response_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "320006f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: company_id: 13, person_id_pc: 757514, created_at_pc: 2024-02-07 11:24:05.462963, customer_id_pc: 7538cb11-1c23-4c76-87c7-5111a0f166dc, id_pc: 24, updated_at_pc: 2024-02-07 11:24:05.462963, person_id_ppl: 757514, name: Alyson Gausby, city: Toronto, region: Ontario, country: CA, company_name: Twitter, seniority_level: Head of ..., title: Head of Research, headline: Head of Research at Twitter Canada, started_on: 2016-06-01, created_at_ppl: 2023-12-11 06:18:08.13904, updated_at_ppl: 2023-10-23 03:55:58.36, institute: [{194859, Wilfrid Laurier University, Bachelor of Business Administration (BBA), Fine and Studio Arts, 2001-01-01, 2005-01-01}], latest_edu_created_at: 2023-12-11 06:18:37.445885, employments: [{13, Twitter, Head of ..., Head of Research, 2016-06-01, null}], latest_emp_created_at: 2023-12-11 06:18:49.396966, urls: [{linkedin, https://www.linkedin.com/in/alyson-gausby-34b20819}, {crunchbase, https://crunchbase.com/person/alyson-gausby}], latest_url_created_at: 2023-12-11 06:18:57.46109, sectors: Social Media, Blogging Platforms, SMS, Messaging, B2C, amount_usd: 5077482000.00, stock_ticker: TWTR, headcount: 3346\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "llamaModelId = 'meta.llama2-70b-chat-v1' \n",
    "\n",
    "# Collect the DataFrame into a list and access the first row\n",
    "rows_list = string_documents_df.collect()\n",
    "prompt = rows_list[0].string_document\n",
    "\n",
    "# Print the first row string document\n",
    "print(\"prompt:\", prompt)\n",
    "\n",
    "prompt = \"What is the difference between a llama and an alpaca?\"\n",
    "\n",
    "#response_text = generate_response(llamaModelId, prompt,1000,0.9,0.2)\n",
    "#print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b14f2f-7c1a-4ddb-a0f4-012ee91193d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411b815-a64f-43fd-baeb-788f52dcfbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce7dd3c-db0c-403e-85ad-9c09d1c41995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b33f47b4-2627-437c-95e4-6c2460aa7e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ExpiredTokenException) when calling the InvokeModel operation: The security token included in the request is expired",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 44\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#llamaModelId = 'anthropic.claude-v2' -> AccessDeniedException\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#llamaModelId = 'amazon.titan-text-lite-v1'\u001b[39;00m\n\u001b[1;32m     42\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the difference between a llama and an alpaca?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 44\u001b[0m response_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllamaModelId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(response_text)\n",
      "Cell \u001b[0;32mIn[22], line 25\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(model_id, prompt, maxGenLen, topp, temp)\u001b[0m\n\u001b[1;32m     14\u001b[0m session \u001b[38;5;241m=\u001b[39m boto3\u001b[38;5;241m.\u001b[39mSession(\n\u001b[1;32m     15\u001b[0m     aws_access_key_id\u001b[38;5;241m=\u001b[39m AWS_ACCESS_KEY_ID,\n\u001b[1;32m     16\u001b[0m     aws_secret_access_key\u001b[38;5;241m=\u001b[39m AWS_SECRET_ACCESS_KEY,\n\u001b[1;32m     17\u001b[0m     aws_session_token\u001b[38;5;241m=\u001b[39mAWS_SESSION_TOKEN\n\u001b[1;32m     18\u001b[0m )  \n\u001b[1;32m     20\u001b[0m bedrock_runtime \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mclient(\n\u001b[1;32m     21\u001b[0m     service_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbedrock-runtime\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m     region_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mus-east-1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mbedrock_runtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodelId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontentType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m response_body \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     33\u001b[0m response_text \u001b[38;5;241m=\u001b[39m response_body[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ExpiredTokenException) when calling the InvokeModel operation: The security token included in the request is expired"
     ]
    }
   ],
   "source": [
    "# tested , working , benchMark, not change\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "def generate_response(model_id, prompt,maxGenLen,topp,temp):\n",
    "   \n",
    "    payload = json.dumps({\n",
    "        'prompt': prompt,\n",
    "        'max_gen_len': maxGenLen,\n",
    "        'top_p': topp,\n",
    "        'temperature': temp\n",
    "    })\n",
    "\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id= AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key= AWS_SECRET_ACCESS_KEY,\n",
    "        aws_session_token=AWS_SESSION_TOKEN\n",
    "    )  \n",
    "\n",
    "    bedrock_runtime = session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=payload,\n",
    "        modelId=model_id,\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    response_text = response_body['generation']\n",
    "\n",
    "    return response_text\n",
    "\n",
    "# Example usage\n",
    "llamaModelId = 'meta.llama2-70b-chat-v1' \n",
    "#llamaModelId = 'anthropic.claude-v2' -> AccessDeniedException\n",
    "#llamaModelId = 'amazon.titan-text-lite-v1'\n",
    "\n",
    "prompt = \"What is the difference between a llama and an alpaca?\"\n",
    "\n",
    "response_text = generate_response(llamaModelId, prompt,512,0.9,0.2)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84ff43a5-bbde-4c29-89ac-edd9c92d947e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid output received from the model.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def generate_response(ModelId, prompt1):\n",
    "      \n",
    "    payload={\n",
    "        \"prompt\":prompt1,\n",
    "        \"maxTokens\":512,\n",
    "        \"temperature\":0.8,\n",
    "        \"topP\":0.8\n",
    "    }\n",
    "\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id= AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key= AWS_SECRET_ACCESS_KEY,\n",
    "        aws_session_token= AWS_SESSION_TOKEN\n",
    "    )\n",
    "\n",
    "    bedrock_runtime = session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=json.dumps(payload),\n",
    "        modelId=ModelId,\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    \n",
    "    if 'outputs' in response_body and response_body['outputs'] and \\\n",
    "       'data' in response_body['outputs'][0] and \\\n",
    "       'text/plain' in response_body['outputs'][0]['data']:\n",
    "        response_text = response_body['outputs'][0]['data']['text/plain']\n",
    "    else:\n",
    "        response_text = \"No valid output received from the model.\"\n",
    "\n",
    "    return response_text\n",
    "\n",
    "# Example usage\n",
    "ModelId = 'ai21.j2-mid-v1' -> No valid output received from the model.\n",
    "#ModelId = 'ai21.j2-ultra-v1' -> No valid output received from the model.\n",
    "#ModelId = 'anthropic.claude-v2' ->AccessDeniedException\n",
    "\n",
    "\n",
    "prompt1 = \"What is the difference between a llama and an alpaca?\"\n",
    "\n",
    "response_text = generate_response(ModelId, prompt1)\n",
    "print(response_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ce515f6-5119-480a-b487-1a55c8ea5102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid output received from the model.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def generate_response(ModelId, prompt1):\n",
    "    payload = {\n",
    "        \"prompt\": prompt1,\n",
    "        \"maxTokens\": 1024,\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        aws_session_token=AWS_SESSION_TOKEN\n",
    "    )\n",
    "\n",
    "    bedrock_runtime = session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=json.dumps(payload),\n",
    "        modelId=ModelId,\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    if 'outputs' in response_body and response_body['outputs'] and \\\n",
    "       'data' in response_body['outputs'][0] and \\\n",
    "       'text/plain' in response_body['outputs'][0]['data']:\n",
    "        response_text = response_body['outputs'][0]['data']['text/plain']\n",
    "    else:\n",
    "        response_text = \"No valid output received from the model.\"\n",
    "\n",
    "    return response_text\n",
    "\n",
    "# Example usage\n",
    "ModelId = 'ai21.j2-ultra-v1'\n",
    "prompt1 = \"What is the difference between a llama and an alpaca?\"\n",
    "\n",
    "response_text = generate_response(ModelId, prompt1)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a471c120-d3db-4ce9-8c1b-fed6bb907159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid output received from the model.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def generate_response(ModelId, prompt1):\n",
    "    payload = {\n",
    "        \"prompt\": prompt1,\n",
    "        \"maxTokens\": 512,\n",
    "        \"temperature\": 0.8,\n",
    "        \"topP\": 0.8\n",
    "    }\n",
    "\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        aws_session_token=AWS_SESSION_TOKEN\n",
    "    )\n",
    "\n",
    "    bedrock_runtime = session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name='us-east-1'\n",
    "    )\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=json.dumps(payload),\n",
    "        modelId=ModelId,\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    if 'outputs' in response_body and len(response_body['outputs']) > 0 and \\\n",
    "       'data' in response_body['outputs'][0] and \\\n",
    "       'text/plain' in response_body['outputs'][0]['data']:\n",
    "        response_text = response_body['outputs'][0]['data']['text/plain']\n",
    "    else:\n",
    "        response_text = \"No valid output received from the model.\"\n",
    "\n",
    "    return response_text\n",
    "\n",
    "# Example usage\n",
    "ModelId = 'ai21.j2-ultra-v1'\n",
    "prompt1 = \"What is the difference between a llama and an alpaca?\"\n",
    "\n",
    "response_text = generate_response(ModelId, prompt1)\n",
    "print(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
