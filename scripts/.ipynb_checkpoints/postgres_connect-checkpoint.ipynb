{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbc28442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, col, concat_ws, row_number, desc\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84ef717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('postgresql_connection') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ef51b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL connection parameters\n",
    "database = \"global_development\"\n",
    "user = \"postgres\"\n",
    "password = \"password\"\n",
    "url = f\"jdbc:postgresql://global-db:5432/{database}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d1b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read table names from PostgreSQL metadata\n",
    "table_names = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"dbtable\", \"(SELECT table_name FROM information_schema.tables WHERE table_schema = 'public') as tables\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ffa3f46-96ad-4b53-ba9c-b6bfcfa7d856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Tables:\n",
      "ar_internal_metadata\n",
      "companies\n",
      "company_annual_revenues\n",
      "company_customers\n",
      "company_events\n",
      "company_funding_round_investors\n",
      "company_funding_rounds\n",
      "company_headcounts\n",
      "company_locations\n",
      "company_names\n",
      "company_sectors\n",
      "company_social_urls\n",
      "company_stock_tickers\n",
      "people\n",
      "person_customers\n",
      "person_educations\n",
      "person_employments\n",
      "person_social_urls\n",
      "schema_migrations\n",
      "processed_data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convert the DataFrame to a list of table names\n",
    "table_list = table_names.select(\"table_name\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Print the list of table names\n",
    "print(\"Available Tables:\")\n",
    "for table_name in table_list:\n",
    "    print(table_name)\n",
    "\n",
    "# Now you can use this list to access each table individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2c5091a-4474-4ebd-94e1-debaaffd239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from a table into a DataFrame\n",
    "def load_table(table_name):\n",
    "    df = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", url) \\\n",
    "        .option(\"dbtable\", table_name) \\\n",
    "        .option(\"user\", user) \\\n",
    "        .option(\"password\", password) \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .load()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b03575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the people related tables into a DataFrame\n",
    "people_df = load_table(\"people\")\n",
    "person_customer_df = load_table(\"person_customers\")\n",
    "person_educations_df = load_table(\"person_educations\")\n",
    "person_employments_df = load_table(\"person_employments\")\n",
    "person_social_urls_df = load_table(\"person_social_urls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to check the uniqueness of the dataframe\n",
    "def check_uniqueness(df, column_name):\n",
    "    # Add a new column 'is_duplicate' that flags if column_name is duplicated\n",
    "    df_duplicates_check = df.withColumn('is_duplicate', count(column_name).over(Window.partitionBy(column_name)) > 1)\n",
    "\n",
    "    # If any 'is_duplicate' is True, then DataFrame is not unique based on column_name\n",
    "    if df_duplicates_check.filter(col('is_duplicate')).count() > 0:\n",
    "        print(f\"DataFrame is not unique based on {column_name}\")\n",
    "    else:\n",
    "        print(f\"DataFrame is unique based on {column_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dde6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_uniqueness(people_df, 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5104f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific columns from the 'people_df' DataFrame, rename the 'id' column to 'person_id',\n",
    "# and concatenate 'address', 'city', 'region', 'postal_code', 'country' columns with a comma separator\n",
    "people_selected_df = people_df.select('id', 'name', 'address', 'city', 'region', 'postal_code', 'country', 'headline','description', 'created_at', 'updated_at')\\\n",
    "                              .withColumnRenamed('id', 'person_id')\\\n",
    "                              .withColumn('address', concat_ws(', ', 'address', 'city', 'region', 'postal_code', 'country'))\n",
    "\n",
    "people_selected_df = people_selected_df.select('person_id', 'name', 'address','headline','description', 'created_at', 'updated_at')\n",
    "\n",
    "# people_selected_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373a32a7",
   "metadata": {},
   "source": [
    "***Transformation for the \"person_customer\" table***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_customer_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e27be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the 'check_uniqueness' function on 'person_customer_df' DataFrame to check if 'person_id' is unique\n",
    "check_uniqueness(person_customer_df,'person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'person_id' and count the number of occurrences of each 'person_id'\n",
    "duplicate_rows = person_customer_df.groupBy('person_id').agg(count('*').alias('count'))\n",
    "\n",
    "# Filter the rows where 'count' is greater than 1 (i.e., 'person_id' is duplicated)\n",
    "duplicate_rows = duplicate_rows.filter(duplicate_rows['count'] > 1)\n",
    "\n",
    "# # Show the duplicate rows\n",
    "# duplicate_rows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bcb62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a window partitioned by person_id and ordered by updated_at in descending order\n",
    "window = Window.partitionBy(\"person_id\").orderBy(desc(\"updated_at\"))\n",
    "\n",
    "# Add a row_number column to the DataFrame\n",
    "person_customer_df = person_customer_df.withColumn(\"rn\", row_number().over(window))\n",
    "\n",
    "# Filter the DataFrame to keep only the rows with rn = 1 (i.e., the latest updated_at for each person_id)\n",
    "person_customer_df = person_customer_df.filter(person_customer_df.rn == 1)\n",
    "\n",
    "# Drop the rn column\n",
    "person_customer_df = person_customer_df.drop(\"rn\")\n",
    "\n",
    "# # Print the DataFrame to verify the result\n",
    "# person_customer_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the 'check_uniqueness' function on 'person_customer_df' DataFrame to check if 'person_id' is unique\n",
    "check_uniqueness(person_customer_df,'person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 'person_id' and 'customer_id' columns from 'person_customer_df' DataFrame\n",
    "people_selected_customer_df = person_customer_df.select('person_id', 'customer_id')\n",
    "\n",
    "# Join 'people_selected_df' with 'people_selected_customer_df' on 'person_id'\n",
    "people_person_customer_df = people_selected_df.join(people_selected_customer_df, on='person_id', how='inner')\n",
    "\n",
    "# people_person_customer_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ad0ee5",
   "metadata": {},
   "source": [
    "***Transformation for \"Person Education\" table***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de6278",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_educations_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17fb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a struct for each institute\n",
    "institute_struct = F.struct(\n",
    "    \"institution_id\", \"institution_name\", \"degree\", \"subject\", \"started_on\", \"ended_on\"\n",
    ")\n",
    "\n",
    "# Group by person_id and collect list of institute details as structs\n",
    "grouped_educations_df = person_educations_df.groupBy(\"person_id\").agg(\n",
    "    F.collect_list(institute_struct).alias(\"education\")\n",
    "    # (\"education - (institution_id, institution_name, degree, subject, started_on, ended_on)\")\n",
    ")\n",
    "\n",
    "person_education_group_df = grouped_educations_df\n",
    "\n",
    "\n",
    "# Show the result\n",
    "person_education_group_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_uniqueness(person_education_group_df, 'person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad77b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining person_education_group_df and people_person_customer_df DataFrames on column named 'person_id'\n",
    "\n",
    "people_person_customer_education_df = people_person_customer_df.join(person_education_group_df, on='person_id') \n",
    "\n",
    "people_person_customer_education_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by person_id and collect list of URL details\n",
    "grouped_urls_df = person_social_urls_df.groupBy(\"person_id\").agg(\n",
    "    F.collect_list(\n",
    "        F.struct(\"url_type\", \"url\")\n",
    "    ).alias(\"urls\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "grouped_urls_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_uniqueness(grouped_urls_df, 'person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69263c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining person_education_group_df and people_person_customer_df DataFrames on column named 'person_id'\n",
    "\n",
    "people_person_customer_education_social_urls_df = people_person_customer_education_df.join(grouped_urls_df, on='person_id') \n",
    "\n",
    "people_person_customer_education_social_urls_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77192dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_person_customer_education_social_urls_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adcc5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that df is your DataFrame\n",
    "df = people_person_customer_education_social_urls_df\n",
    "\n",
    "# Convert DataFrame to JSON\n",
    "json_df = df.toJSON().collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3237eacf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming json_df is your data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_result/person_final_output.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 5\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(\u001b[43mjson_df\u001b[49m, f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json_df' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Assuming json_df is your data\n",
    "with open('final_result/person_final_output.json', 'w') as f:\n",
    "    json.dump(json_df, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
